이번 시간부터는 텍스트 데이터를 전처리하는 과정에 대해 배워보겠습니다.

우선, 텍스트 데이터 전처리에는 정해진 정답은 없으며 데이터와 목적에 따라 달라집니다.

이 과정은 주로 모델의 입력인 단어, 문장, 문서의 vector를 만들기 전에 진행됩니다.



1. 클렌징

텍스트 데이터에서 분석에 오히려 방해가 되는 불필요한 문자나 기호 등을 분석 전에 제거하는 방법입니다.

예를 들어, ★,＜,※ 와 같은 특수 기호나, <head> , &amp; 와 같은 html,xml 태그 등을 제거 합니다.


2. 필터링/ STOPWORD 지정

대회의 목적과 분석자의 재량에 따라 불필요한 단어나 분석에 큰 의미가 없는 단어를 STOPWORD(불용어)로 설정 후 데이터에서 제거해주는 과정입니다.



3. 토큰화(Tokenization)

형태소 분석을 통해 문장을 형태소 단위의 토큰으로 분리합니다.

토큰이란 문법적으로 더 이상 나눌 수 없는 기본적인 언어요소를 뜻합니다. 텍스트 토큰화란 말뭉치로부터 토큰을 분리하는 작업을 뜻합니다.

예를 들어, 'There is an apple' 이라는 말뭉치가 있을 때 이를 토큰화한다고 하면, 'There', 'is',' an', 'apple'로 나뉩니다.



4.Stemming(어간 추출)/ Lemmatization(표제어 추출)

어간 추출이란 단어로 부터 어간을 추출하는 작업을 뜻합니다. 어간 추출은 일부 철자가 훼손된 어근 단어를 추출합니다. 단어를 보고 어림짐작하여 어미를 잘라 어간을 추출하기 때문입니다.

일반적으로 어간 추출보다 표제어 추출이 더 정확히 어근 단어를 찾아줍니다. 품사와 같은 문법적인 요소와 더 의미적인 부분을 감안하기 때문에 어간 추출보다 시간이 더 오래 걸립니다.
